import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.callbacks import get_openai_callback
from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.chains.combine_documents.base import Document
import os
from langchain.text_splitter import CharacterTextSplitter
from datetime import datetime
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)

# OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š
os.environ["OPENAI_API_KEY"] = 'ã“ã“ã«APIã‚­ãƒ¼ã‚’å…¥åŠ›'

def init_page():
    st.set_page_config(
        page_title="è¦ç´„ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ§ "
    )
    st.header("è¦ç´„ã‚¢ãƒ—ãƒª ğŸ§ ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
    st.sidebar.title("ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    st.session_state.costs = []

def init_messages():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
    clear_button = st.sidebar.button("å±¥æ­´å‰Šé™¤", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="")
        ]
        st.session_state.costs = []

def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"

    return ChatOpenAI(temperature=0, model_name=model_name)

def get_text_input():
    text_input = st.text_area("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="input", height=200)
    text_splitter = CharacterTextSplitter(separator="ã€‚", chunk_size=200)
    texts = text_splitter.split_text(text_input)
    return texts

def summarize(llm, docs):
    prompt_template = """
    å…¥åŠ›ã™ã‚‹æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚
    #å…¥åŠ›ã™ã‚‹æ–‡ç« 
    {text:}
    #å‡ºåŠ›å½¢å¼
    è¦ç´„ã—ãŸæ–‡ç« :
    """

    prompt_map = """
    å…¥åŠ›ã™ã‚‹æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚
    #å…¥åŠ›ã™ã‚‹æ–‡ç« 
    {text:}
    #å‡ºåŠ›å½¢å¼
    è¦ç´„ã—ãŸæ–‡ç« :
    """

    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])
    prompt_map = PromptTemplate(template=prompt_map, input_variables=["text"])

    with get_openai_callback() as cb:
        chain = load_summarize_chain( 
            llm,
            chain_type="map_reduce",
            map_prompt=PROMPT,
            combine_prompt = prompt_map,
            collapse_prompt=prompt_map,
            verbose=True
        )

        # Create a Document with page_content set to content
        document = docs
        response = chain({"input_documents": docs}, return_only_outputs=True)
        
    return response['output_text'], cb.total_cost

def main():
    init_page()
    llm = select_model()
    init_messages()

    container = st.container()
    response_container = st.container()

    with container:
        text_input = get_text_input()
        run_button = st.button("å®Ÿè¡Œ")
    start_time = None
    if text_input and run_button:
        document = [Document(page_content=t) for t in text_input]

        with st.spinner("ChatGPT is typing ..."):
            start_time = datetime.now()
            output_text, cost = summarize(llm, document)
        st.session_state.costs.append(cost)
    else:
        output_text = None

    if output_text:
        with response_container:
            st.markdown("## è¦ç´„ã•ã‚ŒãŸæ–‡ç« ")
            st.write(text_input)
            st.markdown("## è¦ç´„ã•ã‚ŒãŸæ–‡ç« ")
            st.write(output_text)

    end_time = datetime.now()
    execution_time = (end_time - start_time).total_seconds() if start_time else None
    if execution_time:
        st.sidebar.markdown(f"**å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’**")
    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

if __name__ == '__main__':
    main()